{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input, models\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datapath = join('data', 'wafer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 백 엔드인 텐서플로우의 세션 설정을 불러옵니다.\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "# 텐서플로우의 ConfigProto() 객체에 학습시 적용할 옵션들을 명시적으로 설정할 수 있습니다.\n",
    "config = tf.ConfigProto()\n",
    "# GPU 옵션으로 allow_grouth를 True로 설정합니다.\n",
    "config.gpu_options.allow_growth = True \n",
    "\n",
    "# 텐서플로우는 세션이라는 실행 단위를 가지고 있는데, 해당 세션에 적용할 옵션을 담고있는 Config객체를 전달합니다.\n",
    "sess = tf.Session(config=config)\n",
    "# 설정한 세션을 현재 프로세스에 적용합니다.\n",
    "set_session(sess)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 살펴보기\n",
    "이번 실습에서 사용할 데이터는 kaggle에 공개되어 있는 Wafer map 데이터 입니다. <br>\n",
    "지난 AutoEncoder 실습에서 Data Augmentation에서 사용을 했었습니다.<br>\n",
    "이번에는 Wafer 이미지를 CNN 네트워크를 통해 Center, Donut, Edge-Loc, Edge-Ring, Loc, Random, Scratch, Near-full, none 9개 종류의 불량 케이스를 분류해보겠습니다.\n",
    "\n",
    "\n",
    "![Kaggle_Wafer](./Images/kaggle_wafer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 행렬 파일로 저장해둔 데이터를 가져옵니다.\n",
    "\n",
    "x = np.load(join(datapath, 'wafermap_class_(26,26).npy'))\n",
    "y = np.load(join(datapath, 'wafer_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape : (14366, 26, 26), y shape : (14366, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 차원을 살펴보겠습니다.\n",
    "print('x shape : {}, y shape : {}'.format(x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty case : ['none'] \n"
     ]
    }
   ],
   "source": [
    "# 0번째 데이터 이미지 확인\n",
    "plt.imshow(x[0])\n",
    "plt.show()\n",
    "\n",
    "# 해당 이미지의 불량 케이스 확인\n",
    "print('Faulty case : {} '.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 검정 부분은 Wafer가 없는 부분으로 0, 초록 부분은 정상을 나타내는 부분으로 1, 노랑 부분은 불량을 나타내는 부분으로 2 값을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 전처리 하기\n",
    "### Wafer 이미지에 채널을 추가하기\n",
    "Wafer 데이터는 26\\*26 이미지이므로 CNN에 넣기 위해서는 채널을 만들어주어야 합니다. <br>\n",
    "numpy.reshape() 함수를 사용해 1개의 채널을 추가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널 추가\n",
    "x = x.reshape((-1, 26, 26, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 불균형을 확인하기\n",
    "먼저 각 불량 케이스 별 데이터들의 불균형을 확인 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불량 케이스 목록 : ['Center' 'Donut' 'Edge-Loc' 'Edge-Ring' 'Loc' 'Near-full' 'Random'\n",
      " 'Scratch' 'none']\n"
     ]
    }
   ],
   "source": [
    "# numpy.unique() 함수는 배열 내에 들어있는 고유한 값들을 반환합니다.\n",
    "faulty_case = np.unique(y)\n",
    "print('불량 케이스 목록 : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center : 90\n",
      "Donut : 1\n",
      "Edge-Loc : 296\n",
      "Edge-Ring : 31\n",
      "Loc : 297\n",
      "Near-full : 16\n",
      "Random : 74\n",
      "Scratch : 72\n",
      "none : 13489\n"
     ]
    }
   ],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(y[y==f])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 불균형이 심한 것을 확인할 수 있습니다. none의 경우 90% 이상의 비율을 차지하고 있습니다.<br>\n",
    "이런 경우 모델이 none 클래스로 찍기만 해도 정확도가 90% 정도가 나올 것을 예상할 수 있습니다. <br>\n",
    "따라서 클래스 불균형 문제를 해결하기 위해 이전 수업에서 사용했던, 생성 모델들을 통해 데이터를 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Ecnoding for categorical variables\n",
    "\n",
    "AutoEncoder에 이미지를 넣기 전에 Wafer 이미지의 픽셀 값은 0, 1, 2의 범주형 변수로 이루어져 있습니다.<br>\n",
    "이를 채널 방향으로 One-hot-Encoding을 진행하면, 모델에게 각 채널별로 범주형 변수를 이해할 수 있도록 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널별로 One-hot-Encoding한 데이터를 담을 틀을 생성합니다.\n",
    "new_x = np.zeros((len(x), 26, 26, 3))\n",
    "\n",
    "for w in range(len(x)):\n",
    "    for i in range(26):\n",
    "        for j in range(26):\n",
    "            new_x[w, i, j, int(x[w, i, j])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb37368ecc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 채널 방향으로 One-hot-Encoding 하기 이전의 이미지\n",
    "plt.imshow(x[1].reshape(26,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb350582208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 채널 방향(axis=2)으로 argmax 취하면, 이전의 이미지와 동일한 이미지를 얻을 수 있습니다.\n",
    "plt.imshow(np.argmax(new_x[1], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14366, 26, 26, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환한 새로운 x의 차원을 살펴보겠습니다.\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터가 준비되었으니, 준비된 데이터로 불균형 문제를 해결해보겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameter\n",
    "epoch=10\n",
    "batch_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder 부분\n",
    "input_shape = (26, 26, 3)\n",
    "input_tensor = Input(input_shape)\n",
    "encode = layers.Conv2D(   , (3,3), activation='')(input_tensor)\n",
    "\n",
    "latent_vector = layers.MaxPool2D()(encode)\n",
    "\n",
    "# Decoder 부분, Decoder는 레이어에 바로 이전 값을 넣지 않고, Layer 자체로 변수로 저장합니다.\n",
    "decode_layer_1 = layers.Conv2DTranspose(, (3,3), activation='')\n",
    "decode_layer_2 = layers.UpSampling2D()\n",
    "output_tensor = layers.Conv2DTranspose(, (3,3), activation='')\n",
    "\n",
    "# 레이어로 저장한 Decoder Layer에 Latent vector 부터 순서대로 Decoding하며 연결합니다.\n",
    "decode = decode_layer_1(latent_vector)\n",
    "decode = decode_layer_2(decode)\n",
    "\n",
    "# AutoEncoder 모델 정의\n",
    "ae = models.Model(input_tensor, output_tensor(decode))\n",
    "\n",
    "# AutoEncoder 모델 생성(컴파일), 최적화기는 Adam, 비용 함수는 mse를 사용합니다.\n",
    "ae.compile(optimizer = 'Adam',\n",
    "              loss = 'mse',\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 학습\n",
    "ae.fit(, ,\n",
    "       batch_size=batch_size,\n",
    "       epochs=epoch,\n",
    "       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder 모델 정의 *compile을 통해 모델을 생성하지 않는 이유는 이미 ae 모델에서 compile과 학습을 마쳤기 때문입니다.\n",
    "encoder = models.Model(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decoder 모델\n",
    "decoder_input = Input((13, 13, 64))\n",
    "decode = decode_layer_1(decoder_input)\n",
    "decode = decode_layer_2(decode)\n",
    "# Decoder 모델 정의, *compile을 통해 모델을 생성하지 않는 이유는 이미 ae 모델에서 compile과 학습을 마쳤기 때문입니다.\n",
    "decoder = models.Model(decoder_input, output_tensor(decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 불량 데이터 인코딩\n",
    "encoded_x = encoder.predict(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 불량 데이터를 축소시켜 만든 Latent 데이터에 약간의 노이즈를 더해 새로운 데이터를 생성 합니다.\n",
    "# numpy.random.normal 함수는 loc=평균, scale=표준편차를 가진 정규 분포 노이즈를 생성 합니다.\n",
    "noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 불량 데이터 확인\n",
    "plt.imshow(np.argmax(new_x[3], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈를 섞어 만든 불량 데이터 확인\n",
    "noised_gen_x = np.argmax(decoder.predict(noised_encoded_x), axis=3)\n",
    "plt.imshow(noised_gen_x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoder가 복원시킨 원본 불량 데이터 확인\n",
    "gen_x = np.argmax(ae.predict(new_x), axis=3)\n",
    "plt.imshow(gen_x[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 AutoEncoder로 추가 데이터를 생성할 수 있습니다. 입력된 불량 케이스마다 2천개 이상의 데이터를 가지고 있도록 데이터를 생성하여 클래스 불균형 문제를 완화하겠습니다. <br>\n",
    "함수 형태로 손쉽게 사용할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(wafer, label):\n",
    "    # 입력 받은 wafer 이미지를 Encoding 합니다.\n",
    "    encoded_x = encoder.predict(wafer)\n",
    "    \n",
    "    # 생성한 wafer 데이터를 모을 틀을 만듭니다.\n",
    "    gen_x = np.zeros((1, 26, 26, 3))\n",
    "    \n",
    "    # 각 클래스가 가지고 있는 데이터의 수가 2천개가 되도록 반복하여 데이터를 생성합니다.\n",
    "    # ex) 가지고 있는 데이터의 수가 2개라면, 2000//2 = 1000, 한번에 2개씩 1000번 2천개의 데이터를 생성합니다.\n",
    "    for i in range((2000//len(wafer)) + 1):\n",
    "        # Encoding한 데이터에 노이즈를 가해 새로운 데이터를 생성합니다.\n",
    "        \n",
    "        #먼저 노이즈를 생성할 데이터의 수만큼 만들고 기존의 데이터에 노이즈를 더해줍니다\n",
    "        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64)) \n",
    "        \n",
    "        #노이즈가 더해진 기존의 Latent Vector를 Decode하여 새로운 값을 생성합니다\n",
    "        noised_gen_x = decoder.predict(noised_encoded_x)\n",
    "        \n",
    "        #만들어진 데이터를 기존의 데이터에 추가해줍니다\n",
    "        gen_x = np.concatenate((gen_x, noised_gen_x), axis=0)\n",
    "        \n",
    "    # 생성한 데이터의 개수에 맞게 레이블도 생성해줍니다.\n",
    "    gen_y = np.full((len(gen_x), 1), label)\n",
    "    \n",
    "    # 데이터를 반환할 때 0번 인덱스에 있는 데이터는 가짜 데이터이므로 제외하고 반환합니다.\n",
    "    return gen_x[1:], gen_y[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 생성을 시작합니다. gen_data 함수에 각 클래스별 wafer 데이터와 라벨을 전달합니다.<br>\n",
    "np.where() 함수를 사용해, 불량 클래스에 맞는 인덱스를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 불량 케이스에 대해 반복문을 수행합니다.\n",
    "for f in faulty_case : \n",
    "    # none 클래스에 대해서는 데이터를 생성하지 않습니다.\n",
    "    if f == 'none' : \n",
    "        continue\n",
    "    # 현재 불량 케이스에 대한 wafer 이미지와, 라벨 값을 전달해 데이터를 생성합니다.\n",
    "    gen_x, gen_y = gen_data(new_x[np.where(y==f)[0]], f)\n",
    "    new_x = np.concatenate((new_x, gen_x), axis=0)\n",
    "    y = np.concatenate((y, gen_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Generate new_x shape : {}, new_y shape : {}'.format(new_x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 생성했으니 클래스 별 분포를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(y[y==f])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "none class를 제외하고, 각 클래스의 데이터가 2천개 정도로 늘어났습니다.<br>\n",
    "none 클래스는 임의 추출을 통해 2천개로 줄이겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace 옵션을 False로 주어 중복 없이 추출하도록 합니다.\n",
    "none_idx = np.where(y=='none')[0][np.random.choice(len(np.where(y=='none')[0]), size=11000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의로 추출한 인덱스로 none 데이터를 제거합니다. \n",
    "# numpy.delete() 함수는 인덱스 번호로 데이터를 제거할 수 있고, axis 를 통해 인덱스 방향을 지정할 수 있습니다.\n",
    "new_x = np.delete(new_x, none_idx, axis=0)\n",
    "new_y = np.delete(y, none_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Delete \"none\" class new_x shape : {}, new_y shape : {}'.format(new_x.shape, new_y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(new_y[new_y==f])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 벡터를 사용하나요\n",
    "여기에서 Label 데이터를 그대로 숫자로 표현해도 되지만, 벡터로 표현한 것은 숫자 이미지라는 특성이 수치적으로 1씩 증가하는 관계가 아니기 때문에<br>\n",
    "서로 독립적인 관계를 갖는 벡터로 표현해주는 것이 더 적절합니다. 이러한 기법을 One-hot encoding이라 합니다.<br>\n",
    "Keras에서는 연속 정수형을 벡터형태로 변환해주는 to_categorical() 함수가 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열로 되어있는 label 값을 숫자 형태로 변경합니다.\n",
    "for i, l in enumerate(faulty_case):\n",
    "    new_y[new_y==l] = i\n",
    "    \n",
    "# label 값을 벡터 형태로 표현합니다.\n",
    "new_y = to_categorical(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전처리가 끝난 데이터를 학습 데이터와 검증 데이터로 나눕니다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_x, new_y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train x : {}, y : {}'.format(x_train.shape, y_train.shape))\n",
    "print('Test x: {}, y : {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN 모델 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (26, 26, 3)\n",
    "input_tensor = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 은닉층\n",
    "conv = layers.Conv2D()(input_tensor)\n",
    "\n",
    "flat = layers.Flatten()(conv)\n",
    "\n",
    "dense = layers.Dense()(flat)\n",
    "\n",
    "# 출력층\n",
    "output_tensor = layers.Dense(9, activation='softmax')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = models.Model()\n",
    "# 모델 생성(컴파일)\n",
    "model.compile(optimizer=,\n",
    "             loss=,\n",
    "             metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "         validation_data=[],\n",
    "         epochs=,\n",
    "         batch_size=,\n",
    "         verbose=2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 그래프를 그립니다.\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 비용 함수 그래프를 그립니다.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터에 대해 어느정도 높은 정확도의 결과를 보여주었습니다.<br>\n",
    "하지만 한가지 주의하셔야 하는 점은 대부분의 데이터가 매우 적은 소수의 데이터에서 생성되었기 때문에 Train, Test로 데이터를 쪼갰다 하더라도<br>\n",
    "모델이 Test 데이터를 관찰하지 않았다고(Unseen Data)하기 어렵습니다. <br>\n",
    "이 부분은 감안하시면 좋겠습니다. 지금까지 고생 많으셨습니다. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
